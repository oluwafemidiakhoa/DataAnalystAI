# pages/0_ðŸ“š_Data_Catalog.py

import streamlit as st
import pandas as pd
import logging
from typing import List, Dict, Any # For type hints

# Get Logger
logger = logging.getLogger(__name__)

# --- Backend/DB Imports (Optional - needed for real data) ---
DB_AVAILABLE = False
try:
    from backend.database import crud, models
    from backend.database.session import get_db_session # Example session management
    DB_AVAILABLE = True
    logger.info("Database components loaded for Data Catalog.")
except ImportError:
    logger.warning("DB components not found. Data Catalog page will use mock/session data.")


# --- Page Config & Title ---
st.set_page_config(page_title="Data Catalog", layout="wide")
st.header("ðŸ“š Data Catalog")
st.markdown("Browse, search, and understand your connected or discovered data sources.")
st.divider()

# --- Load Data Sources ---
data_sources: List[Dict[str, Any]] = [] # Ensure it's initialized as a list of dicts

# Option 1: Load from Database (Preferred if persistence implemented)
if DB_AVAILABLE:
    logger.debug("Attempting to load data sources from database...")
    # try:
    #     with get_db_session() as db:
    #         # Replace with actual CRUD function
    #         # db_sources = crud.get_all_datasources(db, project_id=st.session_state.get('current_project_id'))
    #         # Convert ORM objects to list of dictionaries for UI
    #         # data_sources = [
    #         #     {
    #         #         "id": ds.id, "name": ds.name, "type": ds.source_type,
    #         #         "description": ds.description, "tags": ds.tags or [],
    #         #         "schema": ds.schema_cache.get('schema_string', 'N/A') if ds.schema_cache else 'N/A', # Extract schema string
    #         #         "created_at": ds.created_at
    #         #     } for ds in db_sources
    #         # ]
    #         # Mock DB data for now
    #         data_sources = [{"id": 1, "name": "DB Source 1 (Mock)", "type": "postgresql", "description": "Mock Sales Data", "tags": ["sales", "mock"], "schema": "**Mock Schema DB**\n```text\nTable: orders\n - id (INT)\n - value (FLOAT)\n```"}]
    #         logger.info(f"Loaded {len(data_sources)} sources from DB (mock).")
    # except Exception as e:
    #     st.error(f"Failed to load data sources from database: {e}")
    #     logger.error(f"DB error loading datasources: {e}", exc_info=True)
    pass # Skip DB loading if not implemented

# Option 2: Use currently connected source from session state (Fallback/Alternative)
if not data_sources and 'connection_info' in st.session_state and st.session_state.connection_info:
     logger.info("Using current connection info for Data Catalog display.")
     conn_info = st.session_state.connection_info
     ds_name = conn_info.get('filename') or conn_info.get('db_name') or "Current Session Source"
     # Extract schema string correctly - it might be nested if profiler returns dict
     schema_data = conn_info.get('schema', 'N/A')
     schema_text = schema_data if isinstance(schema_data, str) else schema_data.get('schema_string', 'Schema format unknown or unavailable.') if isinstance(schema_data, dict) else str(schema_data)

     # Extract tags and description if generated by profiler
     profile_data = st.session_state.get('data_profile', {})
     ai_description = profile_data.get('ai_description', '_No AI description available._')
     ai_tags = profile_data.get('ai_tags', [])

     data_sources = [{
         "id": "session_source", # Use a placeholder ID
         "name": ds_name,
         "type": conn_info.get('type', 'N/A'),
         "description": ai_description,
         "tags": ai_tags,
         "schema": schema_text # Use the extracted schema string
     }]


# --- Display Catalog ---
st.markdown(f"Found **{len(data_sources)}** data source(s).")

# --- Search Bar ---
search_term = st.text_input("Search Catalog (by name, type, tag, or description):", key="catalog_search")

# --- Filtering Logic ---
filtered_sources = data_sources
if search_term:
    term = search_term.lower()
    filtered_sources = [
        ds for ds in data_sources if
        term in ds.get('name','').lower() or
        term in ds.get('type','').lower() or
        term in ds.get('description','').lower() or
        any(term in tag.lower() for tag in ds.get('tags', []))
    ]
    st.caption(f"Showing {len(filtered_sources)} matching source(s).")

st.divider()

# --- Display Filtered Sources ---
if not filtered_sources:
    st.warning("No data sources match your search criteria.")
else:
    # Use columns for a card-like layout (optional)
    num_columns = 2 # Adjust as needed
    cols = st.columns(num_columns)
    col_index = 0

    for ds in filtered_sources:
        with cols[col_index % num_columns]: # Cycle through columns
            with st.container(border=True):
                # Display basic info clearly
                st.subheader(f"{ds.get('name', 'Unnamed Source')}")
                st.caption(f"Type: `{ds.get('type', 'N/A')}` | ID: `{ds.get('id', 'N/A')}`")

                # Display Description
                st.markdown(f"**Description:** {ds.get('description', '_N/A_')}")

                # Display Tags
                tags = ds.get('tags', [])
                if tags:
                    tag_markdown = " ".join(f"`{tag}`" for tag in tags)
                    st.markdown(f"**Tags:** {tag_markdown}")

                # Expander for Schema
                with st.expander("View Schema Preview"):
                    # ** FIX: Display the schema string directly **
                    schema_display = ds.get('schema', 'Schema not available.')
                    st.code(schema_display, language='text') # Use st.code for schema

                # Placeholder for actions
                st.button("View Details / Lineage", key=f"details_{ds.get('id', ds['name'])}", disabled=True, use_container_width=True)

        col_index += 1 # Move to the next column

st.divider()
st.caption("_Data Catalog feature under development. More details, lineage, and actions coming soon._")