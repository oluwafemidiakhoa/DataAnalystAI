# backend/data_processing/transformer.py
import pandas as pd
import numpy as np # <--- ADD THIS IMPORT
import logging
from typing import Dict, Any, Optional
# Assuming LLM utils are available for code generation and potentially parsing NL to structured steps
try:
    from backend.llm.gemini_utils import generate_pandas_code_llm # Function that generates pandas code
    # from backend.llm.gemini_utils import parse_nl_to_transform_steps_llm # Ideal: Func that generates structured steps
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.error("LLM utility functions not found for transformer.", exc_info=True)
    # Define mocks
    def generate_pandas_code_llm(schema, command, task): return f"# Mock code for: {command}"
    # def parse_nl_to_transform_steps_llm(schema, command): return []

# Assuming safe execution environment exists (replace with actual import)
# from backend.sandbox.executor import safe_execute_pandas_code # Ideal safe execution
USE_SAFE_EXECUTION = False # Flag indicating if safe executor is available/enabled

logger = logging.getLogger(__name__)

# --- Constants for Transformation Step Types (Example) ---
# Similar to cleaner.py, define constants if using structured steps
COMBINE_COLUMNS = "combine_columns"
CALCULATE_COLUMN = "calculate_column" # Using arithmetic expression
APPLY_FUNCTION = "apply_function" # e.g., log, sqrt, custom func (needs careful handling)
# Add more...


def generate_transformation_code(df_schema: str, nl_command: str) -> str:
    """
    Uses LLM to generate Pandas code for a transformation described in natural language.
    **Note:** This approach is kept for flexibility but carries security risks if executed directly.
              Prefer generating structured steps if possible.

    Args:
        df_schema: A string describing the DataFrame schema (columns and types).
        nl_command: The user's natural language request.

    Returns:
        Generated Python/Pandas code string.

    Raises:
        RuntimeError: If LLM call fails.
    """
    logger.info(f"Generating transformation PANDAS CODE for command: '{nl_command}'")
    if not LLM_AVAILABLE:
        logger.warning("LLM not available, returning basic mock code.")
        return f"# Mock code for: {nl_command}\n# (LLM Unavailable)"

    try:
        # Use the specific LLM function for generating Pandas code
        code = generate_pandas_code_llm(schema=df_schema, command=nl_command, task="dataframe transformation")
        logger.info("Pandas code generated by LLM.")
        return code
    except Exception as e:
        logger.error(f"LLM code generation failed for transformer: {e}", exc_info=True)
        raise RuntimeError(f"AI failed to generate transformation code: {e}") from e


def apply_transformation(df: pd.DataFrame, nl_command: Optional[str] = None, generated_code: Optional[str] = None) -> pd.DataFrame:
    """
    Applies a transformation to a DataFrame, preferably using safe execution.
    Currently relies on executing generated code (UNSAFE MOCK).

    Args:
        df: The input DataFrame.
        nl_command: The original natural language command (for logging lineage).
        generated_code: The Pandas code string generated by the LLM.

    Returns:
        The transformed DataFrame.

    Raises:
        ValueError: If code is missing or execution fails.
        RuntimeError: For unexpected errors.
    """
    if not generated_code:
        raise ValueError("No transformation code provided to apply.")

    # Add 'datasource_id' or other identifier if available for lineage logging
    input_source_id = df.attrs.get('datasource_id', 'unknown_input')
    df_transformed = df.copy() # Work on a copy

    # --- Execute Code (Safely if possible) ---
    execution_method = "unsafe_mock_exec" # Default to unsafe mock
    try:
        if USE_SAFE_EXECUTION:
            # --- Ideal: Use Safe Sandboxed Execution ---
            # execution_method = "safe_sandbox"
            # logger.info(f"Applying transformation using SAFE EXECUTION: \n{generated_code}")
            # # Pass necessary context (df, pd) to the sandbox
            # execution_context = {'df': df_transformed, 'pd': pd, 'np': np} # Add other needed imports
            # # The safe_execute function handles isolation and returns modified df or errors
            # df_transformed = safe_execute_pandas_code(generated_code, execution_context)
            # logger.info("Safe execution completed.")
            pass # Replace pass with actual safe execution call when available

        else:
            # --- Fallback: UNSAFE MOCK EXECUTION (Simulates effect) ---
            logger.warning(f"Applying transformation code (MOCK EXECUTION - UNSAFE): \n{generated_code}")
            print(f"--- MOCK EXECUTION START ---\n{generated_code}\n--- MOCK EXECUTION END ---")
            local_vars = {'df': df_transformed, 'pd': pd, 'np': np} # Provide context
            # --- Simulate known mock codes for demo ---
            if "'full_name'" in generated_code and "'first_name'" in df.columns and "'last_name'" in df.columns:
                df_transformed['full_name'] = df_transformed['first_name'].astype(str) + ' ' + df_transformed['last_name'].astype(str)
            elif "'profit'" in generated_code and "'revenue'" in df.columns and "'cost'" in df.columns:
                df_transformed['profit'] = pd.to_numeric(df_transformed['revenue'], errors='coerce') - pd.to_numeric(df_transformed['cost'], errors='coerce')
            elif "'sales_per_quantity'" in generated_code and "'sales_amount'" in df.columns and "'quantity'" in df.columns:
                 df_transformed['sales_per_quantity'] = df_transformed['sales_amount'].astype(float).divide(df_transformed['quantity'].astype(float).replace(0, pd.NA)).fillna(0)
            else: logger.info("No specific mock transformation simulated.")
            # df_transformed = local_vars['df'] # This line is needed if using real exec()

        # --- Log Lineage (#3) ---
        try:
            # from backend.database.crud import log_lineage_step # Example import
            lineage_details = {'command': nl_command, 'code_executed': generated_code, 'method': execution_method}
            # log_lineage_step(
            #     process_type='transformation',
            #     process_details=lineage_details,
            #     input_source_id = input_source_id,
            #     # Assuming transformation modifies in place conceptually for lineage
            #     output_source_id = input_source_id
            # )
            logger.info(f"Lineage logged for transformation: {lineage_details.get('command', 'N/A')[:50]}...")
        except Exception as lineage_err:
            logger.warning(f"Failed to log lineage for transformation: {lineage_err}")

        return df_transformed

    except Exception as e:
        logger.error(f"Error during {execution_method} of transformation code: {e}", exc_info=True)
        # Re-raise as ValueError to indicate failure to apply the specific transform
        raise ValueError(f"Failed to apply transformation: {e}") from e

# --- Alternative (Safer) Approach: Structured Steps ---
# If you implement parse_nl_to_transform_steps_llm in gemini_utils.py
# you could have a function like this:

# def apply_structured_transformation(df: pd.DataFrame, step_type: str, params: Dict[str, Any]) -> pd.DataFrame:
#     """Applies a predefined transformation step based on structured parameters."""
#     logger.info(f"Applying STRUCTURED transformation step '{step_type}' with params: {params}")
#     df_transformed = df.copy()
#     try:
#         if step_type == COMBINE_COLUMNS:
#              cols = params.get("columns")
#              new_col = params.get("new_column_name")
#              sep = params.get("separator", " ")
#              if not cols or not new_col: raise ValueError("Missing columns or new_column_name.")
#              df_transformed[new_col] = df_transformed[cols].astype(str).agg(sep.join, axis=1)
#              logger.info(f"Combined columns {cols} into '{new_col}'.")
#         elif step_type == CALCULATE_COLUMN:
#              new_col = params.get("new_column_name")
#              expression = params.get("expression") # e.g., "df['col_a'] * df['col_b']" or just "col_a * col_b"
#              if not new_col or not expression: raise ValueError("Missing new_column_name or expression.")
#              # VERY CAREFUL evaluation needed here, ideally parse expression safely
#              # Example using pd.eval (still carries some risk):
#              try:
#                   df_transformed[new_col] = pd.eval(expression, engine='python', local_dict={'df': df_transformed})
#                   logger.info(f"Calculated column '{new_col}' using expression.")
#              except Exception as eval_err: raise ValueError(f"Invalid expression for calculation: {eval_err}") from eval_err
#         # Add more structured steps...
#         else:
#             raise ValueError(f"Unsupported structured transformation step type: {step_type}")

#         # Log Lineage here as well...

#         return df_transformed
#     except Exception as e:
#          logger.error(f"Error applying structured transform step '{step_type}': {e}", exc_info=True)
#          raise ValueError(f"Failed structured transform '{step_type}': {e}") from e